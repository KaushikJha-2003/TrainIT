# TrainIT
IMPACT-X

# ğŸ“š COVID-19 Case Prediction Using Machine Learning

## ğŸ“ Project Description
The COVID-19 pandemic has highlighted the need for accurate case predictions to assist healthcare systems and government agencies in resource allocation and decision-making. This project aims to develop a robust machine learning model to predict the number of confirmed COVID-19 cases based on data from multiple sources, including:

- Daily COVID-19 confirmed cases by state.
- COVID-19 testing data, including the number of tests conducted.
- Vaccination data tracking the administration of vaccines over time.

## ğŸ“‚ Project Directory Structure
```
.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ cases_data.csv         # COVID-19 confirmed cases data
â”‚   â”œâ”€â”€ testing_data.csv       # COVID-19 testing data
â”‚   â””â”€â”€ vaccine_data.csv       # COVID-19 vaccination data
â”œâ”€â”€ notebooks
â”‚   â””â”€â”€ trainit.ipynb          # Main Jupyter Notebook for analysis & training
â”œâ”€â”€ models
â”‚   â””â”€â”€ trained_model.pkl      # Saved trained model
â”œâ”€â”€ results
â”‚   â”œâ”€â”€ feature_importance.png # Plot showing feature importance
â”‚   â””â”€â”€ model_evaluation.png   # Model performance comparison plot
â”œâ”€â”€ utils
â”‚   â””â”€â”€ data_preprocessing.py  # Script for data cleaning & transformation
â”œâ”€â”€ README.md                  # This README file
â””â”€â”€ requirements.txt           # Required Python packages
```

## ğŸ“Š Datasets Used
1. COVID-19 Cases Dataset: Contains the number of confirmed COVID-19 cases reported daily by state.
2. Testing Dataset: Includes the number of COVID-19 tests conducted, positive test rates, and other relevant indicators.
3. Vaccination Dataset: Provides information on vaccine doses administered across different regions.

## ğŸš€ Technologies & Tools Used
- ğŸ“Š Data Analysis: Pandas, NumPy
- ğŸ“ˆ Data Visualization: Matplotlib, Seaborn
- ğŸ¤– Machine Learning: Scikit-learn, XGBoost
- ğŸ” Model Interpretation: SHAP (SHapley Additive exPlanations)
- ğŸ“ Jupyter Notebook: For development and analysis

## ğŸ› ï¸ Project Setup & Installation
### âœ… Prerequisites
Ensure that Python 3.x is installed. Use the following command to check the Python version:
```bash
python --version
```

### ğŸ“¥ Clone the Repository
```bash
git clone [https://github.com/KaushikJha-2003/TrainIT]
cd covid-19-prediction
```

### ğŸ“¦ Install Required Packages
```bash
pip install -r requirements.txt
```

## ğŸ“š Usage Instructions
### ğŸ“ Running the Jupyter Notebook
1. Open the `trainit.ipynb` file in Jupyter Notebook or Google Colab.
2. Run all cells to perform:
    - Data loading and cleaning.
    - Feature selection and transformation.
    - Model training and evaluation.
    - Model explainability using SHAP.


## ğŸ“Š Model Development & Evaluation
### ğŸ“¡ Data Preprocessing
- Merging datasets using date and state as common keys.
- Handling missing values and feature encoding.
- Scaling numerical features for better model performance.

### ğŸ¤– Models Implemented
- Random Forest Regressor
- Decision Tree Regressor
- Logistic Regression
- Bagging and Stacking Regressors
- Voting Regressor
- XGBoost Regressor

## ğŸ§  Model Interpretation with SHAP
SHAP (SHapley Additive exPlanations) was used to identify the most significant features that influence model predictions.

âœ… **Feature Importance Plot**
- Displays the impact of different features on model predictions.

## ğŸ“Š Results & Insights
### ğŸ¥‡ Model Comparison
The performance of all models was compared based on various evaluation metrics.
âœ… Key Findings:
- Random Forest showed the highest accuracy in predicting confirmed cases.
- Testing and vaccination rates were found to be the most influential features.


## ğŸ”¥ Error Analysis & Improvements
- The models underperformed for states with inconsistent data reporting.
- Suggestions for improvement:
    1. Adding more feature variables.
    2. Using time series models like ARIMA or Prophet.
    3. Incorporating external data sources to improve prediction quality.

## ğŸ¤ Contribution Guidelines
1. Fork the repository
2. Create a new branch
3. Make necessary changes and commit
4. Open a pull request for review


